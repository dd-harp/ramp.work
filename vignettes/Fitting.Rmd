---
title: "Set Up Fitting" 
subtitle: "Fitting a Dynamical System to a PfPR Time Series" 
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document 
vignette: >
  %\VignetteIndexEntry{Fitting Models to Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

*** 

**QUICK START** 

**1. Set Up a Model**

First, we set up a model using **`ramp.xds`** setup functions, so we load `ramp.xds.`

```{r}
library(ramp.xds)
```

We choose simple models:

```{r, eval=F}
model <- xds_setup(model, MYname = "SI") 
```

**2. Run Scaling**

For differential equation models, we run `xde_scaling` to set up `model$outputs$eirpr.` This makes it possible to make some good initial guesses for the parameter we will want to fit. This is in `ramp.work,` so we load it: 

and we run `xde_scaling`

```{r, eval=F}
model <- xds_scaling(model) 
```

**3. Set Up Fitting**

Now, we set up fitting, and we pass the `pfpr` time series and the paired `jdates`:  

```{r, eval=F}
model <- setup_fitting(model, pfpr, jdates)
```

During fitting, the *Pf*PR time series `pfpr` and the julian dates `jdates` are stored on the `fitting` object, along with a set of options. 

**4. Fit the model using `pr2history`** 

At this point, we're ready to fit the model: 

```{r, eval=F}
model <- pr2history(model)
```

In the following, we present a longer introduction, a fully worked example, and a discussion of the implementation (for `dev` nerds).

*** 

# Introduction 

**`ramp.work`** was developed with the goal of fitting a malaria model -- a dynamical system of malaria epidemiology, transmission dynamics, and control -- to a *Pf*PR time series. What are we fitting? 

In all these models, we assume that malaria epidemiology is being *forced* by something. When we do the analytics, we want to have some flexibility in choosing what is forcing malaria epidemiology. Given a *Pf*PR time series, we might want to:
  
+ estimate **exposure,** defined by the *Pf*EIR (`eir`); 

+ fit a model with transmission forced by mosquito **emergence** (`Lambda`);  

+ fit a model with mosquito ecology forced by changes in mosquito carrying capacity. 

+ estimate the **effect sizes** of vector control, contigent on a **counterfactual baseline** 

To do the fitting in a sensible way, we need to have some ways of setting and modifying parameters describing *interannual variability.* Since the models are dynamical systems, we need the algorithms to handle some issues that do not affect other kinds of time-series analysis. In particular, the dynamical systems approach forces us to confront the historical context for malaria -- what happened before? We can identify these challenges: 

+ **Hindcast** -- During model fitting, the predicted *Pf*PR will be sensitive to the *initial conditions* that are set when we solve the differential equations. We must thus consider the handling of these initial conditions as a part of the fitting process, and we will need to be attentive to the way the fitting handles a *burn-in* period to set the initial conditions.  

+ The forcing function is decomposed into three parts, a mean ($m$), a seasonal pattern $S(t)$, and a trend, $T(t)$. The functions we use are multiplicative, so $F(t) = m S(t) T(t)$. 

    + **Average** -- we fit the mean value
    
    + **Seasonal Pattern** -- We assume that malaria transmission is seasonal to some extend, so we fit the *phase,* *amplitude,* and *shape* of seasonal forcing. We call it a seasonal *pattern* because we constrain the values of $S(t)$ so that it does not modify the arithmetic mean of $F(t)$.  
    
    + **Trend** -- We set up a **spline** using a set of interpolation points: the $t$ values of the interpolation points are, by default, set to every year. Since $F(t)$ is multiplicative, the average value of $T(t)$ over the year should be close to one.  

+ **Forecast** -- To set up models for scenario planning, we need the ability to do short-term forecasting. We can also use the *forecasting* infrastructure to ensure that there is some consistency about fitting at the end of the time series. 

We handle this in two steps: 

+ **History** -- In the first step, we fit a model to the data disregarding all information about vector control.

    - *Exposure* - one useful intermediate point is to fit a model of the EIR. 
    
    - *Transmission* - alternatively fit a model forced by mosquito emergence, with adult mosquito ecology and a fully-defined model of the transmission dynamics. Since vector control modifies adult mosquito `bionomics`,  the function that we fit is a kind of *naive history* 

+ **Baseline** -- We consider malaria epidemiology and transmission dynamics as a *changing baseline* that has been *modified by control,*  so we need to  **Imputing a Baseline** and then **Evaluate Vector Control.** The problem here is that we have two things to estimate from one time series. The estimate of the effect size is contingent on the imputed value of the baseline. Unless we can become omniscient, there's no way around this conundrum. 

    + In years where we think baseline has been modified by vector control, we need to impute the value of a counterfactual baseline -- what would have happened in the absence of vector control.  
    
    + After setting the counterfactual baseline, we fit the *coverage* parameter for a model for vector control.  From this, we can compute an 
effect size of for each event, contingent on the imputed baseline. 

Once we have done this, we have a model that is ready for **scenario planning.**
    
*** 

# Example 

## Set Up 

### Build 


```{r build, eval=F}
sis_si <- xds_setup(MYZname = "SI")
```

```{r scaling, eval=F}
sis_si <- xde_scaling_lambda(sis_si)
```

```{r saveRDS, eval=F, echo=F}
saveRDS(sis_si, "sis_si.rds")
```

```{r, echo=F}
sis_si <- readRDS("sis_si.rds")
forced_by <- "Lambda"
class(forced_by) <- "Lambda"
sis_si$forced_by <- forced_by
```

### Data 

```{r pfpr time series}
library(ramp.uganda)
get_district_pfpr_i(124) -> prts
```

### Set Up Fitting 

```{r run setup_fitting}
sis_si <- setup_fitting(sis_si, prts$pfpr, prts$jdate)
```

```{r}
show_trend(sis_si)
```

## Baseline  

# Implementation Notes

The following section is for anyone who is interested in the nuts and bolts. We hope it helps you track down errors, and maybe you'll want to get your hands dirty with `ramp.xds` or `ramp.work` development.   

## The Model Fitting Object 

To handle all the tasks seamlessly, we call `setup_fitting` to create a **model fitting** object, attached to the **`ramp.xds`** model object, `model` as `model$fitting.`  We use spline functions to handle the interannual variability. The spline is configured by passing a set of interpolation points $t, y$ (or `ty`) The full set of interpolation points includes three sets: one for the burn-in period; one for the observational period; and one for forecasting. 

To make all of this work generically, we store the object in a generic format to use for model fitting. The data from `model$fitting` are used to recompute a forcing function in any context. 

Model fitting is set up by attaching various compound lists to the **`ramp.xds`** object:  

  
+ `forced_by` :: a string to dispatch functions called during fitting gets stored (options: `Lambda`, `eir`)

+ `data$` :: interpolation points for the observation period

     - `tt` :: the set of $t$ values for interpolation during the observational period 
     
     - `yy` :: the set of $y$ values for interpolation during the observational period 

+ `hindcast$` 
    
     - `tt` :: the set of $t$ values for burning, set by hindcasting 
        
     - `yy` :: the set of $y$ values for burning, set by hindcasting 

+ `forecast$` 
    
     - `tt` :: the set of $t$ values for a forecast 
        
     - `yy` :: the set of $y$ values for a forecast 

+ `fitting$` 
    
     - `tt` :: the full set of $t$ values 
        
     - `yy` :: the full set of $y$ values 
        


This gangly object makes it possible to write other functions that handle all the cases generically. 


## Defaults and Options 

### Goodness of Fit (Option)
